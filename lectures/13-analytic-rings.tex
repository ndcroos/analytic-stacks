% !TeX root = ../AnalyticStacks.tex

\section{\ufs Generalities on analytic rings (Clausen)}
\label{sec:13-analytic-rings}

\url{https://www.youtube.com/watch?v=38PzTzCiMow&list=PLx5f8IelFRgGmu6gmL-Kf_Rl_6Mm7juZO}
\renewcommand{\yt}[2]{\href{https://www.youtube.com/watch?v=38PzTzCiMow&list=PLx5f8IelFRgGmu6gmL-Kf_Rl_6Mm7juZO&t=#1}{#2}}
\vspace{1em}

\begin{unfinished}{0:00}
In the last lecture, Peter was---well, we spent a lot of time talking about solid analytic rings. In the last lecture, Peter started to introduce different kinds of classes of analytic rings which also work in the archimedean context, so these "liquid" and "gaseous" analytic rings.

What I want to do today is I want to talk about some generalities on analytic rings, partially in service of the story Peter is telling, and partially because it sort of should be done at some point. It's going to turn out that when discussing these new examples of analytic rings, it's kind of nice to have a good handle on the category of analytic rings and how to manipulate it. So I'll just be presenting some various facts about analytic rings and their category.

Let me start by recalling the definition. So an analytic ring is a pair $(R, \mathcal{M}_R)$, where $R$ is a condensed, commutative ring, and $\mathcal{M}_R$ is a full subcategory of the category of condensed $R$-modules, closed under limits, colimits, and extensions. Additionally, any $\mathcal{X}$-group in $\mathcal{M}_R$ mapping to any condensed $R$-module still lies in $\mathcal{M}_R$. Finally, the unit object, the underlying ring itself, should lie in this full subcategory. Let's call this last condition "$\star$".

Now I'll make another definition. A "non-complete analytic ring", or "pre-analytic ring", is a pair as above, except we don't require the $\star$ condition. This concept arises when trying to produce an analytic ring structure on an interesting condensed ring, as the $\star$ condition can be quite complicated to verify. Often, there is a simpler ring that maps to the condensed ring, and it's easier to produce a pre-analytic ring structure on that simpler ring. Then, there is a completion procedure that allows one to go from a non-complete analytic ring to a complete, honest analytic ring.

We've seen examples of this when discussing rigid spaces. Recall the solid $R^+$ theory---when specifying the category attached to a rational open, we took the category of $R$-modules and imposed some conditions, which actually made it into a pre-analytic ring. But the $\star$ condition was not necessarily satisfied, so one would need to change the $\mathcal{M}_R$ to basically the structure sheaf to get an honest analytic ring.

In general, what you want to do with these non-complete analytic rings is to complete them to get something that is an analytic ring in the honest sense. That's the procedure I want to discuss right now.

A map of pre-analytic rings is just like a map of analytic rings---a map of underlying condensed rings such that the restriction of scalars of any module in the domain category lands in the module category of the codomain.

The completion function, the $R$-completion going to mod $R$, and then you have the $S$-completion going to mod $S$. So, this is a completion functor exhibiting this as a localization. And similarly here, this condition here is the same thing as saying that if you go here and then you complete, that actually factors through here necessarily uniquely because this is a localization. So, it's saying that if you have a map here which is kill, which goes to an isomorphism here, then it goes to an isomorphism here. So, then you get a symmetric monoidal base change functor from mod $R$ to mod $S$.

So, that defines the category of pre-analytic rings. In other words, there's a fully faithful inclusion of the category of pre-analytic rings into the category of analytic rings, and this inclusion has a left adjoint. Moreover, the left adjoint sends the triangle mod $R$ to---and some explanation will be required, but we take our triangle and we complete it with respect to this pre-analytic ring structure here. So, we apply the left adjoint to the inclusion from mod $R$ into mod $R$ triangle, and then we take, so to speak, the same mod $R$.

So, first, we need to make sure that this is of the appropriate type. I mean, I need to explain how mod $R$ is actually a full subcategory of mod $R$ triangle hat, in order for this to parse as a claim. And then I need to check that this setup satisfies the same axioms as this setup, so it actually defines a pre-analytic ring.

So, first of all, this mod $R$ triangle hat is a commutative condensed ring. This is a sort of a completely general phenomenon. We have this mod $R$ triangle, and this localization functor to mod $R$, this completion functor, this $R$-completion, and this is symmetric monoidal and cocontinuous, and it has a right adjoint, which is the inclusion in this case. But when you have a symmetric monoidal functor with a right adjoint, then the right adjoint is automatically lax symmetric monoidal. And in particular, if you take the unit object here and then you apply the right adjoint, it gets a commutative algebra structure. So, mod $R$ triangle hat is a commutative algebra in this category, in this tensor category, and therefore a fortiori in condensed abelian groups, so it's a condensed commutative ring.

Moreover, in this general situation with the right adjoint to a symmetric monoidal functor, if you take any object here and apply that right adjoint, it gets the canonical structure of a module over this commutative algebra, again just purely formally. So, there's this natural factoring. We have mod $R$ including into mod $R$ triangle, and this actually factors through mod $R$ triangle hat modules, and then the forgetful functor. And the next thing I should check is that this is actually fully faithful, so that we can indeed view mod $R$ not just as a full subcategory of mod $R$ triangle, but of mod $R$ triangle hat.

Completion is idempotent. You find that this is indeed just a triangle M tan, okay?

So, we have to verify all of the axioms, and this is actually a little bit more subtle because we need to make sure that the calculations are going to work out correctly. Let me remark that this argument for full faithfulness will also work for $X$, provided that the derived completion on our triangle is the same as the completion on our triangle.

Recall that we had this notion of the derived category of an analytic ring, which was a full subcategory of the derived category of our triangle, and we had the derived completion functor, which was not necessarily even on something sitting in degree $0$. Its $\pi_0$ or $H^0$ is the same as this, but it could have higher homology. For example, in this situation with these weird non-sheafy adic spaces, we don't have that. But in general, we don't have that. So what we can see is that everything works if we replace our triangle hat by our triangle hat, the derived thing, and use the notion of a derived analytic ring. Meaning that if you ask not to give an analytic ring structure on this ordinary ring, but an analytic ring structure on this derived enhancement, then using the same kind of formal argument, you'll be able to check all of these properties.

So, let's introduce a notion of a derived analytic ring. An analytic $E_\infty$-ring is a pair $R_\triangle, \mathcal{M}_R$, where $R_\triangle$ is a connective condensed $E_\infty$-ring, and $\mathcal{M}_R$ is a full subcategory of $R_\triangle$ that is closed under limits, colimits, and such that the internal $\mathcal{H}om$ from anything in $\mathcal{M}_R$ to anything in $R_\triangle$ is still in $\mathcal{M}_R$.

The proposition is that for any connective condensed $\infty$-ring $R_\triangle$, there exists a bijection between the set of pre-analytic ring structures on $R_\triangle$ and the pre-analytic ring structures on just the condensed commutative ring which is gotten by taking $\pi_0$. This projection on the level of pre-analytic ring structures restricts to a bijection on the level of analytic ring structures. And what is this gotten by? Here, you have this $\mathcal{M}_R$, and you send that to just those things in $\mathcal{M}_R$ which happen to lie in the heart.

As $D = 0 \oplus \pi_0 R \triangle$, so you have a module concentrated in degree zero over some derived ring, that's just the same thing as giving a usual module over the $\pi_0$. And in this direction, it's given by sending $\operatorname{Mod}_R$ to the set of those $M$ in $D \geq 0 R$ such that $H_* M$ is in $\operatorname{Mod}_R$ for all $i \geq 0$. 

So, is this definition that $D > 0$ might not be closed on the limits? Didn't I ask it to be a whole category? I can't repeat the question, but it goes to the greatest than minus one. I mean, yeah, I still have, but we gave the argument fixing that. So when you have this assumption, you can see that that holds. When you take an arbitrary direct sum of copies of the unit, then you'll see that products of a fixed, even higher derived products of a fixed, given fixed element will be still in the category. And then if you have an arbitrary product, then you can write it as a retract of a product with a fixed element by taking the direct sum of all the elements.

So, let me make a remark. In a special case where $R \triangle = \pi_0 R \triangle$, we see that the two definitions are consistent, meaning in the case where the notion of rings overlaps, namely where your derived ring is just concentrated in degree $\mathbb{Z}$, so it is a classical ring, the derived definition of what an analytic ring structure or a pre-analytic ring structure is matches up with the naive definition we gave on the level of $\infty$-categories.

The second remark is this finishes the proof of the proposition on completion, because what we can do is we can just... So there's no obstruction to proving the proposition on completion in the derived setting, and then we can move it down to the $\mathcal{A}n$ setting by going from the analytic ring structure on this derived thing that we produced to the analytic ring structure on its $\pi_0$, just by applying this procedure.

Monoidal category, then you can look at commutative algebra objects in it, and there's an $\infty$-categorical version of that, which implicitly involves things like $\infty$-operads or something. But really, an $E_\infty$-algebra over $\mathbb{Z}$ will just be a commutative algebra object in the derived category of $\mathbb{Z}$ in that $\infty$-category, with the usual derived tensor product.

So if you believe in this $\infty$-category mumbo jumbo, you don't need to think about it in being built in terms of topological spaces and operads explicitly. You can kind of just plug into some simple categorical formalism.

Okay, so that's the notion of completion. Maybe the good thing to say is that you have an analytic ring over here, which gives you an analytic ring over here, such that the analytic ring structures here are the same thing as the analytic ring structures here, and such that each $\pi_i$, not just $\pi_\mathbb{Z}$, is complete in this category here.

I'm not going to prove the proposition, as this was proved in one of the older lectures. You can look there for the argument. Now I want to move on to the next topic, which is colimits in the category of analytic rings, although maybe I should make another remark.

It's important to note that the derived categories can change when you take an analytic ring structure on $\pi_k$. It gives you an abelian category, but we also argue it gives you a derived category. That derived category is not necessarily going to be the same as the derived category you get on $R^\triangle$ when you move along this equivalence, because the higher homology in $R^\triangle$ can make things a little different. 

So when we're doing this completion on the level of naive analytic rings sitting in degree zero, it's important to note that the derived category is not the correct one. If $R^\triangle /R$ is the completion of $R^\triangle /R$, then it's not necessarily true that the derived category of this thing is the same as the derived category of that thing, unless you use derived completion on the left-hand side. If this ring that you calculate has higher homology, then you really should be considering a derived analytic ring instead of an ordinary analytic ring.

Okay, so now we have this notion of completion of analytic rings, and this lets us discuss colimits of analytic rings. The procedure is to take the colimit in pre-analytic rings and then complete. What is this colimit in pre-analytic rings? It's actually quite naive. If you have a diagram $R_i^\triangle /R_i$, then the colimit is just the tensor product of the $R_i^\triangle$ modulo the tensor product of the $R_i$.

Is the co-limit of condensed rings given by taking the co-limit of condensed commutative rings? No, sorry, the co-limit of $R_i$ mod $r_i$ is the pair of the co-limit over $I$ of the $R_i$ and that's the co-limit in condensed commutative rings. Then you take a certain full subcategory, so-called mod cimit $I$ ini $I$ $R_i$, where this is the those $m$ in mod co-limit $R_i$ such that when you restrict scalars to $R_i$, $m$ lies in mod $r_i$. It's just an intersection of a bunch of categories where those categories are just required when you restrict scalars, you lie in the corresponding complete thing.

This is quite straightforward to see from the definition of the category of analytic rings. By definition, a map is a map of rings satisfying a certain property, so you certainly want the co-limit of the rings here, and this definition is just tailored so that you have the correct property. Checking that this satisfies the axioms of a pre-analytic ring is also not difficult. Closure under limits and colimits is elementary, and the closure under the axioms is also not so difficult.

Let me now take some examples. The claim is that for filtered co-limits in analytic rings, the completion is unnecessary. The filtered co-limit of $R_i$ mod filtered co-limit of $r_i$ is already complete. That means that for every $I$, you lie in mod $r_i$, but from $I$ on in this filtered co-limit, you lie in mod $R_i$ by definition, and so from $I$ on, that's a co-final collection, so you can calculate this as a filtered co-limit of things which satisfy the condition, so it also satisfies the condition.

An example of this is that if $R$ is a discrete commutative ring, then solid $R$ is the filtered co-limit of solid $r_i$, $i$ in $I$, if $R$ is the filtered co-limit of the $r_i$.

If you understand filtered co-limits, then the next thing you should try to understand is pushouts. If you have an $R \to A \to B$ diagram of analytic rings, then you need to complete the pre-analytic ring which is a tensor over $R$ of $B$, and then the full subcategory of those $m$ in mod $A$ tensor $R$ $B$ such that as an $A$-module, that lies in mod $A$ and as a $B$-module, it lies in mod $B$. It is important to complete here, because this thing has no reason to lie in mod $A$ or in mod $B$. The completion functor here a priori involves iterating an $A$-completion and a $B$-completion, alternating it one category or the other. The exact same remarks apply in the infinity category if you know the notion of derived analytic ring.

In general, you'd have to take this thing $A$-completed as an $A$-module, then $B$-complete that as a $B$-module, then $A$-complete that and $B$-complete that, pass to a sequential co-limit, and that would be the description of the completion functor. In practice, it's usually not so bad, but that's a priori what you need to do.

You enforce all of the relations described by your rational open. So if it was $\mathcal{F}_{1}$ over $G$, then you require that $gx$ is invertible on your modules, and that $\mathcal{F}$ over $G$ is a solid variable with respect to all of your modules. And then the pushouts---so a new analytic ring, I hesitate to call it $\mathcal{O}(U)^{+}$, but okay, I'll do it anyway. Maybe. And then if you take $\mathcal{O}(U)^{+}$ tensor over $R$ with some other $\mathcal{O}(V)^{+}$, then what you're going to get is the same thing for the intersection of these rational opens: the analytic ring corresponding to the intersection of these rational opens. I guess in the discrete case, our discrete it literally is just this. 

So the notion of pushout in analytic rings is corresponding to intersection of rational opens here, and that just follows from the definition of this. So yeah, these pushouts are in general kind of the most important construction, because they're geometrically what's supposed to correspond to pullbacks. And this business of having to complete them makes for an additional subtlety compared to the usual algebraic geometry.

Okay, so questions about that. Is the procedure easier when you just want a finite product? No, the case of relative tensor products is no easier. The case of absolute tensor products is no easier than the case of relative tensor products. So in fact, I could have---I didn't really need in this first part to say filtered, sifted is enough if you know what sifted means. And then general colimits, just as general colimits can be decomposed into filtered colimits and pushouts, general colimits can also be composed with sifted colimits and coproducts. So concretely, the completion functor for this relative tensor product is just the same as the completion functor for the absolute tensor product.

Okay, now I want to have a little bit of fun, well, depending on your definition of fun. I want to prove the following theorem. Suppose $R$ is an analytic ring. Then the Frobenius map, which goes from $R$ to $R/P$, induced by $x \mapsto x^p$, is certainly a map of condensed rings. But this is actually a map of analytic rings, from $R$ to $R/P$. And the $R/P$-modules are just the $R$-modules that are complete when viewed as $R$-modules.

You should probably assume $R$ has characteristic $p$, in which case it's really just a map from $R$ to $R$. What do we need to do to prove such a claim? Well, according to the definition, what we need to do is to see that if $M$ is in $\mathrm{Mod}_R$, then the Frobenius pushforward of $M$, which lies in $\mathrm{Mod}_{R/P}$, actually lies in $\mathrm{Mod}_R$. This is not so obvious how to check. We have these maxims of analytic rings, they're all about closure, categorical closure properties in linear algebra, like limits and colimits and so on, they say absolutely nothing about the Frobenius. They give no kind of hint as to why this should be true. However, let me make a remark: there is another perspective on maps of analytic rings.

To be a map, a map of analytic rings, you need to check a priori for all $S$-modules. But, by co-limits, it's enough to check it for a generating class. In fact, you know, so for these guys, in fact you can even take $T$ to be the countable set if you like, so that this is the thing that you actually get, is that this is an $R$-module. So the map from the free $R$-module on $T$ to it factors through $RT$, and this is functorial in $S$, functorial in $T$.

Moreover, well, there's a small extra condition that in particular is satisfied by them. So, if you do have a map from $T$ to $R$-triangle, a map of condensed sets from $T$ to $R$-triangle, then there's two things you can do. One, you can make a map from $R[T]$ to $R$-triangle, an $R$-triangle linear map, because by definition of analytic ring, this thing is complete. You go to $R$-triangle $[T]$ and then you go to $R[T]$. But then you also have this map here that we've assumed exists from $R[T]$ to $S[T]$, but on the other hand, you can compose this to $S$-triangle, and you get this thing here. So this is just a map of rings, this is the thing we posited to exist, and this exists for the same reason this exists, and that square will commute when you have a map of analytic rings.

So I want to claim---conversely, if $R \to R$-triangle to $S$-triangle is a map of condensed rings, such that there exist these maps from $RT$ to $ST$ satisfying the conditions above, then $R \to S$ is a map $R \to S$.

This is nice because you don't have to explicitly think about how you'd build $S[T]$ from $R[T]$-modules if you just have the maps that would kind of indicate it. Then you can actually do it. Let me maybe give a hint of the argument---it's in the notes from a previous iteration of this. A hint of the argument would be that $\text{Mod}_R$ is monadic over condensed sets, so you have a forgetful functor from $\text{Mod}_R$ to $\text{mod}_R$-triangle, which in turn forgets to condensed sets, and that satisfies the hypothesis of Barr-Beck. It's basically a localization, or the right adjoint of a localization, followed by a forgetful functor. And so this category can be understood as the category of whatever they call it, algebra over some monad here, which is kind of the free $R$-module monad. And then if you want to show that every $S$-module is an $R$-module, it would be enough to produce a map of monads from the free $R$-module monad to the free $S$-module monad. Well, the very first step in producing such a map of monads would be giving the map from the free object here to the map of the free object here, and then there's a condition you need to check, compatibility with the monad structure. And if you play around enough, you can reduce what you need to check to just this commutative diagram here.

Okay, so let's continue discussing Fenu's. So now what are we reduced to? We need, for every compact Hausdorff space $T$, a

Recognize that each of those cross terms is a norm from $M \otimes \mathbf{P}$, so it's a nice exercise if you've never done it.

Sorry, continue over here. I should say you have a group homomorphism---that's the special thing that happens here.

And what is the relation of this construction with the Frobenius on a ring? If $M = R$ is a commutative ring, then you have this thing which goes from $R$ to $R \otimes_\mathbf{P} \mathbf{T}^\mathbf{P}$ and $\pi_0$ of that. But then you can use the multiplication map from $R \otimes \mathbf{P}$ to $R$, to go to this where now the $\mathbf{T}^\mathbf{P}$ action is trivial. Here you're using that the ring is commutative, so that the multiplication is a $\mathbf{T}^\mathbf{P}$-equivariant map from $R \otimes \mathbf{P}$ to $R$. But now since the $\mathbf{T}^\mathbf{P}$ action is trivial, this is just the same thing as the norm map, which is just summing over the action of the group, but the group is trivial, so you're just summing over $\mathbf{P}$ copies of 1. So this really is just $\mathbf{R}_\mathbf{P}$. And if you trace through this, this is the Frobenius.

Okay, and now if $M$ is an $R$-module, then this map, the so-called Frobenius map from $\mathbf{T}^\mathbf{P}$, is a map of abelian groups. In fact, it is a map of $R$-modules if you Frobenius twist on the right-hand side. In other words, this abelian group level Frobenius is kind of linear over the ring level Frobenius, in the appropriate sense.

What this suggests is that we should try to apply this abelian group version of Frobenius and see what happens. So now we take $T$ a profinite set, then we get $R[[T]]$, and we can always do this construction. Now we're viewing $R[[T]]$ as a sheaf of abelian groups on profinite sets, and we can apply this construction here. We tensor it $\mathbf{P}$ times, and we get $\mathbf{T}^\mathbf{P}$, and then we take $\pi_0$. So that's all just happening at the level of sheaves of abelian groups.

We can always map this to any further completion we like, and in particular we can map it to $\pi_0 R[[T]]$, which is the free $R$-module on the profinite set $T$. We have this sort of Künneth formula, so the tensor products of the free modules are just the free modules on the product, and then $\mathbf{T}^\mathbf{P}$ is acting here as well.

We wanted to make a map from $R[[T]]$ to itself which is Frobenius-linear, and we've gotten to $R[[T]]$ to the $\mathbf{P}$. How do we compare them? Well, we can put $R[[T]]$ into this via the diagonal embedding, and that's also equivariant for the $\mathbf{T}^\mathbf{P}$ action if you make $\mathbf{T}^\mathbf{P}$ act trivially here.

The claim is that this map is an isomorphism. If you buy that, then you're basically done. $\mathbf{T}^\mathbf{P}$ is acting trivially here, so the Tate construction is just modding out by $\mathbf{P}$, so this is indeed $\mathbf{R}_\mathbf{P}[[T]]$. And for similar reasons, the composite is actually going to be Frobenius-linear and give you the desired construction. You also have to check that condition, but the full argument is in the notes

Well, we're going to more directly use them now. So the proof is: the first claim is that R[SCP] is actually mapping injectively into R[S], and the reason is that any inclusion of light profinite sets has a retraction. This was a fact that Peter proved in the second lecture of this course. So if you apply it to the inclusion of CP and S, you find there's a retraction. So then if you hit it with any functor, it'll still be injective.

So what does this imply? This implies by the long exact sequence in take-chology that it suffices to show that if you take R[S] mod R[SCP], this thing has vanishing take-chology.

The second claim is that generally, if you have T inside S, then $R[S] mod R[T]$ only depends on the locally compact space, the locally light profinite space which is the complement $S\setminus T$. It's not like a group, where you can choose.

Okay, so that's not a precise claim. What's the more precise version of the claim? If you have S' mapping to S, and then you have T included here, and you form the pullback to get T', and if this is an isomorphism over S minus T, so you're sort of blowing up T, so to speak, or you're choosing a different compactification of S minus T, then R[S'] mod R[T'] maps isomorphically to R[S] mod R[T], and this holds because this square here is a pushout in condensed sets, which is a little exercise you can see using the definition of the Grothendieck topology.

And then the third thing is that if X is a sigma-compact, totally disconnected, locally compact Hausdorff space, and CP acts with no fixed points, then X is actually isomorphic to some coproduct of CP many copies of Y, where CP is acting by permuting those copies. Sigma-compact means countable union of compacts.

Okay, so if you combine two and three, what do you deduce? You deduce that in that setting, R[S] mod R[SCP] is actually a direct sum of CP many copies of some guy X, where CP is acting on this set.

Copies of some guy and then you compact a in a different way by just compactifying $Y$ and then taking the $\mathbb{C}P^n$ many disjoint union copies of that to get a compactification of $X$ and then use that to calculate the quotient here. Then you'll find that the module is induced, and an induced module has vanishing Tate cohomology.

Okay, so this fact that $\mathcal{F}$ is a map of analytic rings, it's not just a cute fact. I'll make a remark, but I don't think I'll go into the details. This theorem on $\mathcal{F}$ implies that if our triangle mod $R$ or let's do it in this setting of a derived analytic ring or a pre-analytic ring, and we give our triangle the structure of an animated commutative ring or condensed ring, which gives new functors like derived symmetric powers on $D^{\geq 0}_R$, which are the things used to build free animated rings or the monad describing animated rings over our triangle, then these symmetric powers descend. If a map $M \to N$ goes to an isomorphism in $D^{\geq R}_R$, then its symmetric powers also go to isomorphisms there. This allows you to do normalization or completion of pre-analytic rings in the animated context, giving a good category of animated analytic rings.

Okay, so one last topic. I'll call it "killing algebra objects". Recall for motivation that we presented the solid $\mathbb{Z}$-theory as the analytic ring structure on the integers where $M$ is in solid $\mathbb{Z}$ if and only if the internal Hom from $P$ to $M$, shifted by -1, is an isomorphism. This is equivalent to saying that $\mathrm{Hom}(A, M) = \mathbb{Z}$, where $A = P / (T-1)$. This has an algebra structure in the ambient category $D_{\mathbb{Z}}^{\mathrm{cond}}$. 

In general, if $C$ is a symmetric monoidal category, we can consider "killing algebra objects" $A$ in $C$, and the category of modules over $A$ in $C$. The condition that a map $M \to N$ goes to an isomorphism in the localization $D^{\geq R}_R$ allows you to extend symmetric power functors from this thing to that localization.

Let's say we have a monoidal, presentable, stable infinity category, and let's include that the tensor product commutes with co-limits in each variable. Let's say A and C is an algebra object, and it really, I only need it in some kind of weak sense. So let's say that we have a multiplication map, literally just A tensor A goes to A. We have a unit, so there's the unit object in the symmetric monoidal category, and then we require that the multiplication is either left or right unital.

So let's say one is the unit for A, and then the multiplication is an isomorphism. You said you don't require any associativity or nothing, yeah, it's really, really weak. Okay, then we can define D subset C to be the full subcategory of those M in C such that the internal Hom, which implicitly is an RHom here, from A to M equals zero. So we're killing A, we're declaring that A should be equal to zero, but also in an internal Hom sense. And then the goal will be, in favorable situations, to give a formula for the left adjoint to the inclusion, to the inclusion. Sorry, is K the name of the mathematician or just "killing"? Killing, killing, killing means not the mathematician responsible for the killing. I'm that this kind of seem, probably he didn't do it, yeah.

Okay, maybe I should give some examples. Well, there was the solid example that I just described. So there was also solid ZT, which was also obtained by killing some endomorphism of, or requiring some endomorphism of P to go to an isomorphism, but that endomorphism of P was also just given by multiplication by some element with respect to the ring structure on P, so it's the same thing as killing the cofiber, just like this. There's also kind of pure algebra examples. So for example, if you take the usual derived category D of R, and then you look at R mod f, so that's called D of R, then what is D? Well, D is D of R1 over F, so it's kind of inverting f in some algebraic sense, is an example of this. Another thing you could do is call D of R, then you could take this algebra instead, R bracket f inverse in D of R, then what is D? D is the sort of like f-complete derived subcategory, and we're looking for a formula for the derived F completion.

Okay, so let's define a functor F from C to C by the following. F of X is the internal Hom from C to X, and there's a natural transformation from X to F of X because this is the same thing as internal Hom from 1 to X, and by construction, C maps to 1, so you get a map in the other way on the internal Hom. I want to claim that this is a first step towards constructing the required localization. Claim: if M is in D, then applying P to M to this map is an isomorphism. So Homing to M living in D doesn't see the difference between X and F of X.

Okay, so for the proof, it suffices to see that the fiber of X mapping to F of X is an A-module. The reason for that is to show that Homing out of this map to M being an isomorphism is the same thing as saying that the Homs from the fiber to M should be zero. But by definition, internal Homs from anything in A to M is zero. Therefore, if it's an A-module, then it's actually a unital---maybe I should say it's a retract of A tensor

And one should actually potentially be a bit careful about which map one writes down here. What I want to do is I want to take $F$ applied to the previous map, as opposed to taking the instance of the previous map with $X$ replaced by $F(x)$.

Okay, and then you can continue on like this: $F(f(f(x)))$. And then I claim that, so let's define $F_\infty(x)$ to be the colimit of this sequence. Then I claim that, if either (1) this colimit stabilizes for all $X$, so if for example every map from here onward is an isomorphism, or (2) the internal $\text{Hom}$ functor from $C$ to $C$ commutes with colimits, or really maybe only needs sequential colimits, then $X \mapsto F_\infty(X)$ is the left adjoint to the inclusion of $D$ inside $C$.

For the proof, you have to check two things. One, you have to check that if you map from $X$ to anything in $D$, that's the same thing as mapping from $F_\infty(X)$ to anything in $D$. But we just proved that claim for $X$ going to $f(X)$, and this thing is given by hitting an instance of that map with the functor $F$. But the functor $F$ is going to preserve the property used in the proof here that the fiber is an $A$-module, because internal $\text{Hom}$ to an $A$-module will still be an $A$-module. So the exact same argument shows that each of these maps also satisfies the same property that internal $\text{Hom}$ out of them doesn't see the difference between one guy and the next. And then you have a colimit, and internal $\text{Hom}$-ing out of that is just an inverse limit of internal $\text{Hom}$-ing out of all the other ones. So that formally just passes through to the colimit.

Okay, so in principle, for example, you can just you could at least attempt to use this formula to compute solidification. It's all actually quite explicit. In that case, this $\text{Hom}$-ing out of $C$ is just...

It's also fun to try to unwind these cases and see that you recover the classical formulas. For example, the well-known formula for $M_1/F$ can be rewritten as a sequential colimit, which is exactly the same as this sequential colimit formula. 

Here, it looks different because it's an inverse limit, but what's actually happening is that this inverse limit is just the first iteration of $f(x)$ applied to $M$, and all the maps after that are isomorphisms. So it's a way to understand the left adjoints using this formula.

I should also mention that this situation occurs when $a$ is idempotent. But this is not the case here, so taking the completion would not give you the same result. You'd be doing something else, not just algebraically inverting $F$. 

I went a little over time, so I apologize for that. Thank you, and see you next week.
\end{unfinished}